---
title: "BC LTC Analysis"
author: "KT Hobbs"
date: "02/08/2020"
output:
  html_document: default
  pdf_document: default
---

## Import and prepare the data
```{r results="hide"}
library(skimr)

# Import the data
df <- read.csv("../data/BC/bc_ltc_complete_kt.csv", na.strings="", header=TRUE)
colnames(df)
```

```{r}
# assess ROOMS and BEDS_TOTAL
cor(df[, c(16:19)], use = "pairwise.complete.obs")
```

```{r}
# assess complaints and subcomplaints
df$COMPLAINTS <- as.numeric(as.character(df$COMPLAINTS))
df$SUB_COMPLAINTS <- as.numeric(as.character(df$SUB_COMPLAINTS))
cor(df[, c(10:15)], use = "pairwise.complete.obs")
```

Only keep `DCH_TOTAL_CURRENTYR`.

```{r}
# assess complaints and subcomplaints
df$COMPLAINTS <- as.numeric(as.character(df$COMPLAINTS))
df$SUB_COMPLAINTS <- as.numeric(as.character(df$SUB_COMPLAINTS))
cor(df[, c(20,21)], use = "pairwise.complete.obs")
```


Remove homes with suppressed data (4) and special units (3) as they are included as part of a major building already.

```{r}
rmv <- c(# suppressed data
              "Bella Coola General Hospital", "Mackenzie and District Hospital and Health Centre",
                "Northern Haida Gwaii Hospital and Health Centre", "R. W. Large Memorial Hospital",
              
         # special care units
               "Berkley Care Centre - Special Unit", "Fair Haven - Vancouver - Special Unit",
              "Harmony Court Care Centre  - Special Unit")

df2 <- df[-which(df$FACILITY_NAME %in% rmv),]

# remove incidents that are NOT per 100 beds
colnames(df2)
df2 <- df2[, -c(22:29, 30:37)]

```


```{r}
# drop unneccessary columns
dr <- c(#"FACILITY_NAME", - keep for data quality analysis
        "HCC_CODE", "STREET_ADDRESS", "CITY", "POSTAL", # deemed irrelevant to inquiry
        "COMPLAINTS", # substantiated complaints are more telling
       "DCH_NURSE_LASTYR", "DCH_ALLIED_LASTYR", "DCH_TOTAL_LASTYR",
       "DCH_NURSE_CURRENTYR", "DCH_ALLIED_CURRENTYR", 
       "THERAPY_PT", "THERAPY_RT", "THERAPY_OT", "RESTRAINTS",
       "ISE", # high multicollinearity
       "latitude", "longitude",
       # "AGE", # redundant - from pairs plot
       "Total.Confirmed.Cases", "Total.Deaths" # focus on outbreak status first
       )

df2 <- df2[, -which(names(df2) %in% dr)]

```

```{r}
# dataframe without health authority 
df3 <- df2[, c(1, 3:length(df2))]
names(df3)
```


### Cleaning
  * Remove unneccesary `INFRACTIONS_`
  * Convert `FEMALE` and `AGE` variables to numeric (from factor) decimals
  * Assess collinearity
  * Convert NAs to "unknown"
  * Bin `FEMALE` and `AGE` variables
  

```{r}
df3 <- df3[,-c(27:38)]
```

  
```{r}
df3$FEMALE <- as.numeric(gsub("[\\%,]", "", df3$FEMALE))/100
df3$AGE <- as.numeric(gsub("[\\%,]", "", df3$AGE))
df3$AGE_85_PLUS <- as.numeric(gsub("[\\%,]", "", df3$AGE_85_PLUS))/100
df3$AGE_UNDER_65 <- as.numeric(gsub("[\\%,]", "", df3$AGE_UNDER_65))/100
```

```{r}
# assess age
age <- c('AGE', 'AGE_85_PLUS', 'AGE_UNDER_65')
pairs(df3[,which(names(df3) %in% age)])
```

"pairwise.complete.obs" then the correlation or covariance between each pair of variables is computed using all complete pairs of observations on those variables.

```{r}
cor(df3[,c(10,12,13)], use = "pairwise.complete.obs")
```



```{r}
# assess councils
# names(df3)
cor(df3[,c(28:29)])
```

I'm decided to keep `AGE_85_PLUS` because there are no missing variables (`AGE` has 3) and seems to be a comorbidity for COVID-19.


```{r}
df3 <- df3[,-which(names(df3) %in% c("AGE", "AGE_UNDER_65"))]
```


  * Convert resident profile information to numeric
  * Convert variables to numeric


```{r}
df3$DEPRESSION <- as.numeric(gsub("[\\%,]", "", df3$DEPRESSION))/100
df3$ADL_DEPENDENT <- as.numeric(gsub("[\\%,]", "", df3$ADL_DEPENDENT))/100
df3$CPS_SEVERE <- as.numeric(gsub("[\\%,]", "", df3$CPS_SEVERE))/100
df3$DEMENTIA <- as.numeric(gsub("[\\%,]", "", df3$DEMENTIA))/100
df3$ABS_PHYS_ABUSIVE <- as.numeric(gsub("[\\%,]", "", df3$ABS_PHYS_ABUSIVE))/100
df3$ISE_LOW <- as.numeric(gsub("[\\%,]", "", df3$ISE_LOW))/100
df3$MEDS_DEPRESSION <- as.numeric(gsub("[\\%,]", "", df3$MEDS_DEPRESSION))/100
df3$MEDS_ANTIPSYCHOTICS <- as.numeric(gsub("[\\%,]", "", df3$MEDS_ANTIPSYCHOTICS))/100
df3$STAY_LENGTH <- as.numeric(gsub("[,]", "", as.character(df3$STAY_LENGTH)))
df3$SUB_COMPLAINTS <- as.numeric(as.character(df3$SUB_COMPLAINTS))
df3$CMI <- as.numeric(as.character(df3$CMI))
```

  * Bin values to preserve homes with missing information.

```{r suppressMessages = TRUE}
binme <- c("FEMALE", "AGE_85_PLUS", "DEPRESSION", "ADL_DEPENDENT", "CPS_SEVERE", "DEMENTIA", "ABS_PHYS_ABUSIVE",
             "MEDS_DEPRESSION", "MEDS_ANTIPSYCHOTICS", "ISE_LOW", "CMI", "STAY_LENGTH", "SUB_COMPLAINTS",
           "DCH_TOTAL_CURRENTYR")
```

```{r}
library(OneR)


for (b in binme){
  # print()
  df3[,paste(b, "BIN", sep= "_")] <- bin(df3[,b], nbins = 3, method = "content", na.omit = FALSE)
}

names(df3)
```

Remove non-binned variables for one dataframe and retain only those for another

```{r}

df3 <- df3[,-c(32:length(df3))]
df_binned <- df3[,-which(names(df3) %in% binme)]
names(df3)
```


### Assess NAs

```{r}
colSums(is.na.data.frame(df_binned))
``````

```{r}
colSums(is.na.data.frame(df3))
``````


### Skewness and Transformations

```{r}
library(skimr)
```

`ROOMS_PRIVATE` distribution not improved with square transform.

`BEDS_TOTAL` distribution not imporved with log transform.

```{r}
# Create a list of right skewed numeric variables with 0 values
# colSums(df3 == 0)

list_non0s = c('BEDS_TOTAL')
list0s = c("ROOMS_PRIVATE", "ROOMS_SEMI", "ROOMS_MULTI",
  "BEDS_PRIVATEprop")


library(rcompanion)

# Visualize the effect of square root transformations on the numeric predictors
for (each in list0s) {  
  plotNormalHistogram(x = df_binned[[each]], main = each)
  plotNormalHistogram(x = sqrt(df_binned[[each]]), main = c(each, 'sqrt trans'))
}

# Visualize the effect of log transformations on the data with no 0s that are right skewed
for (each in list_non0s) {  
  plotNormalHistogram(x = df_binned[[each]], main = each)
  plotNormalHistogram(x = log(df_binned[[each]]), main = c(each, 'log trans'))
}


```

Apply transformations where suitable.

```{r}
df3[list0s] <- sqrt(df3[list0s])

df_binned[list0s] <- sqrt(df_binned[list0s])

skim(df_binned)
```

# Binary Logistic Regression on Original Data (not binned)

Remove `FACILITY_NAME` and `deaths`

```{r}
df4 <- df3[,-which(names(df3) %in% c("FACILITY_NAME", "deaths"))]
df_bin_glm <- df_binned[,-which(names(df_binned) %in% c("FACILITY_NAME", "deaths"))]
```

NAs will be omitted by default.


```{r}
fit2 = glm(outbreak~., family=binomial, data=df4, maxit = 25)
summary(fit2)
```

```{r}
car::vif(fit2)
```

## LASSO On Binned Data
**Should account for multicollinearity.**

```{r}
library(glmnet)
# df_noNA <- na.omit(df4)

x <- model.matrix(outbreak~., df_bin_glm)[,-10]
y <- df_bin_glm$outbreak
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
```

The plot displays the cross-validation error according to the log of lambda. The left dashed vertical line indicates that the log of the optimal value of lambda is approximately -5, which is the one that minimizes the prediction error. This lambda value will give the most accurate model. The exact value of lambda can be viewed as follow:

```{r}
coef(cv.lasso, cv.lasso$lambda.min)
```

Generally, the purpose of regularization is to balance accuracy and simplicity. This means, a model with the smallest number of predictors that also gives a good accuracy. To this end, the function cv.glmnet() finds also the value of lambda that gives the simplest model but also lies within one standard error of the optimal value of lambda. This value is called lambda.1se

```{r}
coef(cv.lasso, cv.lasso$lambda.1se)
```

---

# Group LASSO on Original (unbinned) Data

```{r suppressMessages = TRUE}
library(grpreg)
```

Assign variables to group domains

```{r}
home_info <- c("OWNERSHIP", "REGULATION", "ACCRED_STATUS", "BEDS_TOTAL",
               "ROOMS_PRIVATE", "ROOMS_SEMI", "ROOMS_MULTI", "BEDS_PRIVATEprop",
               "RESIDENT_COUNCIL", "FAMILY_COUNCIL")

resident_info <- c("FEMALE", "AGE_85_PLUS", "DEPRESSION", "ADL_DEPENDENT",
                   "CPS_SEVERE", "DEMENTIA","ABS_PHYS_ABUSIVE", "ISE_LOW",
                   "CMI", "MEDS_DEPRESSION", "MEDS_ANTIPSYCHOTICS")

care_quality <- c("INSPECTIONS", "INFRACTIONS", "INCIDENT_OUTBREAK_100_CAT", "INFRACTION_DISEASE_CAT", "SUB_COMPLAINTS", "DCH_TOTAL_CURRENTYR", "STAY_LENGTH") ## HOW to categorize stay_length?
```


```{r}
df_noNA <- na.omit(df4)
X <- model.matrix(outbreak~., data=df_noNA)[,-24]
Y <- df_noNA$outbreak
dim(X)
```


```{r}
n <- colnames(X)
g <- c()

for (i in 1:length(n)){
  g[i] <- ifelse(n[i] %in% home_info, "homeinfo", 
                 ifelse(n[i] %in% resident_info, "residentinfo",
                        ifelse(n[i] %in% care_quality, "carequality", "misc")))
  }


group<-as.factor(g)
```

```{r}
groupfit <- cv.grpreg(X, Y, group, penalty="cMCP")
plot(groupfit)
```

```{r}
summary(groupfit, "AIC")
```

```{r}
predict(groupfit, type="groups", lambda=groupfit$lambda.min)# Identity of nonzero groups

predict(groupfit, type="vars", lambda=groupfit$lambda.min)# Identity of nonzero coefficients
```

